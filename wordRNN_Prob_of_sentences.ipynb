{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wordRNN Prob of sentences.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOlm9sJJ5TBCvxuoH+psh20",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LabdhiSheth/Deep-Learning-lab-work/blob/main/wordRNN_Prob_of_sentences.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYH23pwuOiGU"
      },
      "source": [
        "from tensorflow import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, SimpleRNN, Embedding\n",
        "from nltk import sent_tokenize\n",
        "from nltk import word_tokenize\n",
        "import numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udb7py5nmdj3",
        "outputId": "a93a25a0-86b8-40d2-8a5f-1076457c940b"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7JMlQVdSKjH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f2a667f-4cea-4522-ba4d-2c37014020f8"
      },
      "source": [
        "input_data = input(\"Enter a few sentences\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter a few sentencesJack and Jill went up the hill . To fetch a pail of water . Jack fell down and broke his crown . And Jill came tumbling after .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCGMOTVYT7YW",
        "outputId": "cd9de005-2ab4-4f00-f395-95ad2a81b1b2"
      },
      "source": [
        "tokenized_sent = sent_tokenize(input_data)\n",
        "tokenized_sent"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Jack and Jill went up the hill .',\n",
              " 'To fetch a pail of water .',\n",
              " 'Jack fell down and broke his crown .',\n",
              " 'And Jill came tumbling after .']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0caoW4LiULXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4ea86c9-3695-49ac-fc9e-d69bc853b27c"
      },
      "source": [
        "tokenizer = Tokenizer(filters = '!\"#$%&()*+,-/:;<=>?@[\\]^_`{|}~')\n",
        "tokenizer.fit_on_texts(tokenized_sent)\n",
        "print(tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'.': 1, 'and': 2, 'jack': 3, 'jill': 4, 'went': 5, 'up': 6, 'the': 7, 'hill': 8, 'to': 9, 'fetch': 10, 'a': 11, 'pail': 12, 'of': 13, 'water': 14, 'fell': 15, 'down': 16, 'broke': 17, 'his': 18, 'crown': 19, 'came': 20, 'tumbling': 21, 'after': 22}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu48UWhGUzaZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c7d1b74-8469-4b94-cbbe-8b54c243db34"
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eyt_kYGfnVyt",
        "outputId": "51886a03-ee5c-4d15-cd3d-5fa46e4408bc"
      },
      "source": [
        "sequence = tokenizer.texts_to_sequences(tokenized_sent)\n",
        "length = len(sequence)\n",
        "print(\"Sequence:\",sequence)\n",
        "print(type(sequence))\n",
        "print(length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequence: [[3, 2, 4, 5, 6, 7, 8, 1], [9, 10, 11, 12, 13, 14, 1], [3, 15, 16, 2, 17, 18, 19, 1], [2, 4, 20, 21, 22, 1]]\n",
            "<class 'list'>\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbhmIrmEnpN7",
        "outputId": "4d759828-d536-4503-fdec-a669b763657b"
      },
      "source": [
        "X = []\n",
        "y = []\n",
        "maxlen = 0\n",
        "\n",
        "for i in range(length):\n",
        "  X.insert(i,sequence[i][:-1])\n",
        "  y.insert(i,sequence[i])\n",
        "  maxlen = max(maxlen,len(sequence[i]))\n",
        "\n",
        "print(X)\n",
        "print(y)\n",
        "print(maxlen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3, 2, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14], [3, 15, 16, 2, 17, 18, 19], [2, 4, 20, 21, 22]]\n",
            "[[3, 2, 4, 5, 6, 7, 8, 1], [9, 10, 11, 12, 13, 14, 1], [3, 15, 16, 2, 17, 18, 19, 1], [2, 4, 20, 21, 22, 1]]\n",
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKZHcEVdn5vw",
        "outputId": "7f8330e3-09d7-4db6-d484-7f6f0277e422"
      },
      "source": [
        "X = pad_sequences(X,maxlen = maxlen+1, padding = 'pre')\n",
        "print(X)\n",
        "y = pad_sequences(y, maxlen = maxlen+1, padding = 'pre')\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0  0  3  2  4  5  6  7  8]\n",
            " [ 0  0  0  9 10 11 12 13 14]\n",
            " [ 0  0  3 15 16  2 17 18 19]\n",
            " [ 0  0  0  0  2  4 20 21 22]]\n",
            "[[ 0  3  2  4  5  6  7  8  1]\n",
            " [ 0  0  9 10 11 12 13 14  1]\n",
            " [ 0  3 15 16  2 17 18 19  1]\n",
            " [ 0  0  0  2  4 20 21 22  1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-h2gaYDqo-6j",
        "outputId": "dda43f37-e430-466a-cd1d-b5bf8779df33"
      },
      "source": [
        "y = to_categorical(y,vocab_size)\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "       [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "       [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "         0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "       [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0L--xJ7pKqU",
        "outputId": "a2d33ef6-5d59-455b-ad82-c1262dc20567"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim = vocab_size,output_dim=50))\n",
        "model.add(SimpleRNN(units=70,return_sequences = True))\n",
        "model.add(Dense(units=vocab_size,activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 50)          1150      \n",
            "_________________________________________________________________\n",
            "simple_rnn_1 (SimpleRNN)     (None, None, 70)          8470      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, None, 23)          1633      \n",
            "=================================================================\n",
            "Total params: 11,253\n",
            "Trainable params: 11,253\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGziShtypvOR",
        "outputId": "5e85ce25-3f12-4269-bac0-20b5ec1382d1"
      },
      "source": [
        "print(\"input shape of all layers:\",model.layers[0].input_shape,model.layers[1].input_shape,model.layers[2].input_shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input shape of all layers: (None, None) (None, None, 50) (None, None, 70)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5wsu9OcqXSL",
        "outputId": "e9e97601-c311-4a0b-a209-d64627ee807e"
      },
      "source": [
        "model.compile(optimizer='rmsprop',loss = 'categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(X,y,epochs=200,verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.1353 - accuracy: 0.0000e+00\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.0475 - accuracy: 0.3611\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.9677 - accuracy: 0.3333\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.8733 - accuracy: 0.4167\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7691 - accuracy: 0.3889\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6741 - accuracy: 0.3889\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5923 - accuracy: 0.4167\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5166 - accuracy: 0.4444\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4436 - accuracy: 0.4444\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.3726 - accuracy: 0.5000\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3035 - accuracy: 0.5000\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2368 - accuracy: 0.5833\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1733 - accuracy: 0.5833\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1133 - accuracy: 0.6111\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0554 - accuracy: 0.5833\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0000 - accuracy: 0.6389\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.9459 - accuracy: 0.6111\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.8945 - accuracy: 0.6667\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8449 - accuracy: 0.6389\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.7971 - accuracy: 0.6667\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.7508 - accuracy: 0.6389\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7058 - accuracy: 0.7500\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.6619 - accuracy: 0.7222\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.6193 - accuracy: 0.7222\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.5776 - accuracy: 0.7222\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5372 - accuracy: 0.7500\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4981 - accuracy: 0.7500\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4605 - accuracy: 0.7500\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4242 - accuracy: 0.7500\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3893 - accuracy: 0.7500\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3544 - accuracy: 0.7500\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.3207 - accuracy: 0.7500\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.2867 - accuracy: 0.7500\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.2542 - accuracy: 0.7500\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.2221 - accuracy: 0.7500\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.1914 - accuracy: 0.7500\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.1611 - accuracy: 0.7778\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.1321 - accuracy: 0.7778\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.1034 - accuracy: 0.8056\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.0760 - accuracy: 0.7778\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0488 - accuracy: 0.8056\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0226 - accuracy: 0.8333\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.9966 - accuracy: 0.8333\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9716 - accuracy: 0.8611\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.9465 - accuracy: 0.8333\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9224 - accuracy: 0.8611\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.8983 - accuracy: 0.8611\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8752 - accuracy: 0.8611\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8522 - accuracy: 0.8611\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8300 - accuracy: 0.8611\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8081 - accuracy: 0.8611\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7869 - accuracy: 0.8611\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7659 - accuracy: 0.8611\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7457 - accuracy: 0.8611\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.7258 - accuracy: 0.8611\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7065 - accuracy: 0.8611\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6874 - accuracy: 0.8611\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6690 - accuracy: 0.8611\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6509 - accuracy: 0.8611\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6334 - accuracy: 0.8611\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6162 - accuracy: 0.8611\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5996 - accuracy: 0.8611\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5833 - accuracy: 0.8611\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5675 - accuracy: 0.8611\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5521 - accuracy: 0.8611\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5373 - accuracy: 0.8611\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5228 - accuracy: 0.8611\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5088 - accuracy: 0.8889\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4953 - accuracy: 0.8611\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4822 - accuracy: 0.8889\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4695 - accuracy: 0.8889\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4573 - accuracy: 0.8889\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4455 - accuracy: 0.8889\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4342 - accuracy: 0.8889\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4232 - accuracy: 0.8889\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4126 - accuracy: 0.8889\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4025 - accuracy: 0.8889\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3927 - accuracy: 0.8889\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3832 - accuracy: 0.8889\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3742 - accuracy: 0.8889\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3654 - accuracy: 0.8889\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3570 - accuracy: 0.8889\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3489 - accuracy: 0.8889\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.3411 - accuracy: 0.8889\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3337 - accuracy: 0.8889\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3265 - accuracy: 0.8889\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3196 - accuracy: 0.8889\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3129 - accuracy: 0.8889\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3065 - accuracy: 0.8889\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3004 - accuracy: 0.8889\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2945 - accuracy: 0.8889\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2890 - accuracy: 0.8889\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2838 - accuracy: 0.8889\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2791 - accuracy: 0.8889\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2745 - accuracy: 0.8889\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2701 - accuracy: 0.8889\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2653 - accuracy: 0.8889\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2607 - accuracy: 0.8889\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2562 - accuracy: 0.8889\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2521 - accuracy: 0.8889\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2481 - accuracy: 0.8889\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2444 - accuracy: 0.8889\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2408 - accuracy: 0.8889\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2375 - accuracy: 0.8889\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2342 - accuracy: 0.8889\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2311 - accuracy: 0.8889\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2281 - accuracy: 0.8889\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2253 - accuracy: 0.8889\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2227 - accuracy: 0.8889\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2201 - accuracy: 0.8889\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2177 - accuracy: 0.8889\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2155 - accuracy: 0.8889\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2133 - accuracy: 0.8889\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2112 - accuracy: 0.8889\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2091 - accuracy: 0.8889\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2072 - accuracy: 0.8889\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2052 - accuracy: 0.8889\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2033 - accuracy: 0.8889\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2012 - accuracy: 0.8889\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1993 - accuracy: 0.8889\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1975 - accuracy: 0.8889\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1958 - accuracy: 0.8889\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1942 - accuracy: 0.8889\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1928 - accuracy: 0.8889\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1914 - accuracy: 0.8889\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1903 - accuracy: 0.8889\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1891 - accuracy: 0.8889\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1880 - accuracy: 0.8889\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1869 - accuracy: 0.8889\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1856 - accuracy: 0.8889\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1844 - accuracy: 0.8889\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1832 - accuracy: 0.8889\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1821 - accuracy: 0.8889\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1812 - accuracy: 0.8889\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1806 - accuracy: 0.8889\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1802 - accuracy: 0.8889\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1800 - accuracy: 0.8889\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1791 - accuracy: 0.8889\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1780 - accuracy: 0.8889\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1766 - accuracy: 0.8889\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1756 - accuracy: 0.8889\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1747 - accuracy: 0.8889\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1739 - accuracy: 0.8889\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1732 - accuracy: 0.8889\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1726 - accuracy: 0.8889\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1720 - accuracy: 0.8889\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1716 - accuracy: 0.8889\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1712 - accuracy: 0.8889\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1710 - accuracy: 0.8889\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1709 - accuracy: 0.8889\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1708 - accuracy: 0.8889\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1701 - accuracy: 0.8889\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1693 - accuracy: 0.8889\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1684 - accuracy: 0.8889\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1678 - accuracy: 0.8889\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1672 - accuracy: 0.8889\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1668 - accuracy: 0.8889\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1666 - accuracy: 0.8889\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1666 - accuracy: 0.8889\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1669 - accuracy: 0.8889\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1671 - accuracy: 0.8889\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1668 - accuracy: 0.8889\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1659 - accuracy: 0.8889\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1652 - accuracy: 0.8889\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1645 - accuracy: 0.8889\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1640 - accuracy: 0.8889\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1636 - accuracy: 0.8889\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1633 - accuracy: 0.8889\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1631 - accuracy: 0.8889\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1629 - accuracy: 0.8889\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1629 - accuracy: 0.8889\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1630 - accuracy: 0.8889\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1632 - accuracy: 0.8889\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1634 - accuracy: 0.8889\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1630 - accuracy: 0.8889\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1625 - accuracy: 0.8889\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1618 - accuracy: 0.8889\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1614 - accuracy: 0.8889\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1610 - accuracy: 0.8889\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1608 - accuracy: 0.8889\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1606 - accuracy: 0.8889\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1605 - accuracy: 0.8889\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1604 - accuracy: 0.8889\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1607 - accuracy: 0.8889\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1613 - accuracy: 0.8889\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1621 - accuracy: 0.8889\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1624 - accuracy: 0.8889\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1617 - accuracy: 0.8889\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1609 - accuracy: 0.8889\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1599 - accuracy: 0.8889\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1595 - accuracy: 0.8889\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1592 - accuracy: 0.8889\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1590 - accuracy: 0.8889\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1589 - accuracy: 0.8889\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1588 - accuracy: 0.8889\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1589 - accuracy: 0.8889\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1591 - accuracy: 0.8889\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1594 - accuracy: 0.8889\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1597 - accuracy: 0.8889\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1595 - accuracy: 0.8889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdef222e510>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qXcvSWdq5I4"
      },
      "source": [
        "def prob_of_input_sentence(model, tokenizer, sentence):\n",
        "  print(\"Input Sentence:\", sentence)\n",
        "  encoded = tokenizer.texts_to_sequences([sentence])[0]\n",
        "  encoded.insert(0,0)\n",
        "  encoded = numpy.array(encoded)\n",
        "  encoded = numpy.reshape(encoded,newshape = (1,-1))\n",
        "  print(\"Encoded:\",encoded,encoded.shape)\n",
        "  prob = model.predict_proba(encoded, verbose=1)\n",
        "  print(\"Probability:\",prob,prob.shape)\n",
        "  probability = 1\n",
        "  for i in range(prob.shape[1]-1):\n",
        "    #probability = probability * prob(0,i,encoded[0,i+1])\n",
        "    probability = probability * prob[0,i,encoded[0,i+1]]\n",
        "    \n",
        "  print(\"Probability of sentence\",\"\\\"\",sentence,\"\\\"\",\"is:\",probability)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZBS9yI_3FX6",
        "outputId": "c09a2680-964d-4ea6-d662-70b4a1d1e7fb"
      },
      "source": [
        "prob_of_input_sentence(model,tokenizer,\".\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Sentence: .\n",
            "Encoded: [[0 1]] (1, 2)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Probability: [[[9.9703276e-01 2.0084874e-04 1.8969362e-05 7.2615716e-04 6.6023854e-06\n",
            "   2.2085409e-05 1.2339698e-04 6.2985651e-05 2.1342496e-05 1.2065714e-03\n",
            "   1.1883777e-06 5.8769921e-05 4.0546238e-05 1.5261008e-04 2.1093027e-05\n",
            "   2.7750077e-06 1.2801871e-04 3.0213960e-05 4.5324487e-05 2.4249115e-05\n",
            "   2.9393579e-05 6.6631665e-06 3.7367161e-05]\n",
            "  [2.5651455e-02 5.0981664e-05 1.0466456e-02 9.5162040e-01 2.9611154e-05\n",
            "   2.6988813e-05 5.2712181e-05 1.3598591e-03 1.2721923e-04 8.8133331e-04\n",
            "   1.8700563e-03 2.2086599e-06 1.6864600e-04 7.4092968e-05 2.4545901e-03\n",
            "   4.4153263e-03 2.8789439e-06 2.9660290e-04 7.6537654e-05 2.7151118e-05\n",
            "   1.9690115e-05 3.0548387e-04 1.9806997e-05]]] (1, 2, 23)\n",
            "Probability of sentence \" . \" is: 0.00020084873540326953\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
            "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnA0q29a3MiT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}